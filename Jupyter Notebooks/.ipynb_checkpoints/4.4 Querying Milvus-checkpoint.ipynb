{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760fdb78",
   "metadata": {},
   "source": [
    "Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029515af",
   "metadata": {},
   "source": [
    "Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1a5d211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, DataType, CollectionSchema, FieldSchema, Collection, Partition, utility\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from openai.embeddings_utils import get_embedding\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2640e5",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d173c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = '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'\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "embedding_encoding = \"cl100k_base\"\n",
    "max_tokens = 8000\n",
    "dimensions =1536\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865f2cc6",
   "metadata": {},
   "source": [
    "Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "90da63d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_name = 'rmrj_articles'\n",
    "bundled_schema = {'rmrj_articles': ['author', 'title', 'published_date', 'text']}\n",
    "collection_names = bundled_schema.get(partition_name)\n",
    "json_path = 'rmrj/rmrj.json'\n",
    "description = 'description'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f356b6",
   "metadata": {},
   "source": [
    "Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "64a22e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=embedding_model):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f5a08",
   "metadata": {},
   "source": [
    "Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "198f14bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[193], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     connections\u001b[38;5;241m.\u001b[39mremove_connection(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Disconnect if it exists\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Now, reconnect with your new configuration\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mconnections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43malias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m19530\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pymilvus/orm/connections.py:349\u001b[0m, in \u001b[0;36mConnections.connect\u001b[0;34m(self, alias, user, password, db_name, token, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m parsed_uri\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    346\u001b[0m             kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecure\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m     \u001b[43mconnect_milvus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# 2nd Priority, connection configs from env\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pymilvus/orm/connections.py:282\u001b[0m, in \u001b[0;36mConnections.connect.<locals>.connect_milvus\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m t \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m timeout \u001b[38;5;241m=\u001b[39m t \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)) \u001b[38;5;28;01melse\u001b[39;00m Config\u001b[38;5;241m.\u001b[39mMILVUS_CONN_TIMEOUT\n\u001b[0;32m--> 282\u001b[0m \u001b[43mgh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_channel_ready\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    284\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pymilvus/client/grpc_handler.py:119\u001b[0m, in \u001b[0;36mGrpcHandler._wait_for_channel_ready\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m         \u001b[43mgrpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannel_ready_future\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_channel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_identifier_interceptor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user)\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/grpc/_utilities.py:151\u001b[0m, in \u001b[0;36m_ChannelReadyFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/grpc/_utilities.py:99\u001b[0m, in \u001b[0;36m_ChannelReadyFuture._block\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mFutureTimeoutError()\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Check if the connection already exists\n",
    "if connections.has_connection('default'):\n",
    "    connections.remove_connection('default')  # Disconnect if it exists\n",
    "\n",
    "# Now, reconnect with your new configuration\n",
    "connections.connect(alias='default', host='localhost', port='19530')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e8a9ca",
   "metadata": {},
   "source": [
    "Input and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb483b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vectors = get_embedding(\"Jovelyn C. Cuizon\")\n",
    "query_vectors = np.array(query_vectors)\n",
    "if len(query_vectors.shape) == 1:\n",
    "    query_vectors = query_vectors.reshape(1, -1)\n",
    "\n",
    "search_params = {\n",
    "    \"metric_type\": \"L2\",  # Distance metric, can be L2, IP (Inner Product), etc.\n",
    "    \"offset\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a032d9",
   "metadata": {},
   "source": [
    "Searching function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5224b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for name in collection_names:\n",
    "    collection = Collection(f\"{name}_collection\")\n",
    "    collection.load()\n",
    "    result = collection.search(\n",
    "        data=query_vectors,\n",
    "        anns_field=\"embeds\",\n",
    "        param=search_params,\n",
    "        limit=5,\n",
    "        partition_names=[partition_name],\n",
    "        output_fields=[name, 'uuid'],\n",
    "        consistency_level=\"Strong\"\n",
    "    )\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b52121",
   "metadata": {},
   "source": [
    "Results sorting by distance and removal of duplicates (smaller distance is kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8c9ebc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to hold unique results\n",
    "unique_results = {}\n",
    "\n",
    "for i, name in enumerate(collection_names):\n",
    "    for result in results[i]:\n",
    "        for item in result:\n",
    "            uuid = item.entity.get('uuid')\n",
    "            data = {\n",
    "                'uuid': uuid,\n",
    "                name: item.entity.get(name),\n",
    "                'distance': item.distance\n",
    "            }\n",
    "            \n",
    "            # If this UUID is not in the dictionary, or it is but the new distance is smaller, update the entry\n",
    "            if uuid not in unique_results or item.distance < unique_results[uuid]['distance']:\n",
    "                unique_results[uuid] = data\n",
    "\n",
    "# Convert the dictionary back into a list of dictionaries\n",
    "results_object = list(unique_results.values())\n",
    "\n",
    "# Sort the results by distance\n",
    "sorted_results = sorted(results_object, key=lambda x: x['distance'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6ff943",
   "metadata": {},
   "source": [
    "Top 5 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9c2fdf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = sorted_results[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d128e2e",
   "metadata": {},
   "source": [
    "Field completion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7e1a377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in final_results:\n",
    "    for name in collection_names:\n",
    "        if name not in result:\n",
    "            collection = Collection(f\"{name}_collection\")\n",
    "            query = f'uuid == \"{result[\"uuid\"]}\"'\n",
    "            query_result = collection.query(\n",
    "                expr=query, \n",
    "                offset=0, \n",
    "                limit=1, \n",
    "                partition_names=[partition_name], \n",
    "                output_fields=[name], \n",
    "                consistency_level=\"Strong\"\n",
    "            )\n",
    "            if query_result:\n",
    "                result[name] = query_result[0][name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140bda76",
   "metadata": {},
   "source": [
    "Printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7243d50b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 0:  {'uuid': '8f41c6f2-c7ca-4af7-9d48-ea4d10648dfc', 'author': 'Jovelyn C Cuizon', 'distance': 0.010531416162848473, 'title': 'Assessing Applicant Employability Using Social Media for Talent Acquisition and Recruitment in IT/BPM Companies', 'published_date': '2019-06-06 June 06, 2019', 'text': 'title: Assessing Applicant Employability Using Social Media for Talent Acquisition and Recruitment in IT/BPM Companies, keywords: social media, background check, cyber-vetting, character assessment, author: Jovelyn C Cuizon, doi: https://doi.org/10.32871/rmrj1907.01.04, abstract: The study aims to assess the extent of social media usage in talent acquisition in IT/BPM companies in Cebu and evaluate the insights of the applicants on the practice of using social media in character assessment for hiring decision. The quantitative method was employed to obtain data from two groups of respondents which constitute thirty hiring managers and ninety-six applicants. The study found that while hiring managers moderately practice social media background check to obtain additional information about the applicant, they seldom used it in hiring decisions because of the lack of formal or informal policy allowing or restricting the use of social media for that purpose. It is also found that there is a significant difference in perception between hiring managers and prospective applicants on usergenerated content on candidate social media profile., published date: 2019-06-06, link: https://rmrj.usjr.edu.ph/rmrj/index.php/RMRJ/article/view/631, journal name: Recoletos Multidisciplinary Research Journal Vol. 7 No. 1'} \n",
      "\n",
      "Result 1:  {'uuid': '9f75127c-2f6c-406a-8101-4f9f5694448e', 'author': 'Jovelyn Cuizon, Kent Ferolino', 'distance': 0.17489570379257202, 'title': 'Social Media Character Assessment for Talent Selection using Natural Language Processing', 'published_date': '2017-10-11 October 11, 2017', 'text': 'title: Social Media Character Assessment for Talent Selection using Natural Language Processing, keywords: social media analytics, text mining, NLP, author: Jovelyn Cuizon, Kent Ferolino, doi: https://doi.org/10.32871/rmrj1705.01.02, abstract: This study aims to use social media data as corpus to assess personâ€™s character to provide a preliminary background check on job seekers. It will provide recruiters an initial assessment of the candidates as well as supplementary information to support traditional recruitment and talent acquisition activities thereby reducing time and cost spent for character investigation. The application uses social media analytics to assign a social profile score. Unstructured text data are preprocessed to include only keywords which are relevant to the analysis. Word sense disambiguation is applied to determine the underlying meaning of the words. The bag-of-word is then checked for occurrence of associated words defined for each factor. Posts containing at least one occurrence of words associated with the factors are further tested for content polarity. Social character score is computed using proposed formula. The system recommends applicants based on skills and uses social character score for relevancy ranking of candidates relative to the job posts., published date: 2017-10-11, link: https://rmrj.usjr.edu.ph/rmrj/index.php/RMRJ/article/view/245, journal name: Recoletos Multidisciplinary Research Journal Vol. 5 No. 1'} \n",
      "\n",
      "Result 2:  {'uuid': '1b92bbb3-d5bb-4ee5-a863-29e4f9913bbb', 'author': 'Claudette A. Baluran', 'distance': 0.23965150117874146, 'title': 'Fun and Fearless: Magazine Covers, Feminine Ideologies, and Representations', 'published_date': '2018-06-30 June 30, 2018', 'text': 'title: Fun and Fearless: Magazine Covers, Feminine Ideologies, and Representations, keywords: multimodal critical discourse, feminine ideologies, magazine cover, language and media, representation, author: Claudette A. Baluran, doi: https://doi.org/10.32871/rmrj1806.01.01, abstract: Starting with the assumption that media, particularly magazines, serve as a ground that shape the ideological landscape for women representations, this paper explored feminine ideologies and representations of twelve (12) Cosmopolitan Philippines magazine covers from the year 2015. Underlying ideological structures were found not only in the linguistic but symbolic features of the text as well.Â  Employing the methodologies of multimodal critical discourse analysis, the investigation revealed emerging patterns on how women are portrayed and represented in the magazine covers.Â  The â€œfun and fearlessâ€ catchphrase that the magazine has shaped to define the modern Filipina (a) presents them as hypersexualized and practicing adventurous sex, (b) positions them as followers of health and beauty regimens and glamorous lifestyle that ultimately lead to the affirmation of the opposite sex, and (c) objectifies them through come-hither poses and scantily-clad bodies that emphasize the cleavage, toned abdomens, and legs.Â  The paper also discussed the possible implications brought about by the perpetuation of these ideological structures., published date: 2018-06-30, link: https://rmrj.usjr.edu.ph/rmrj/index.php/RMRJ/article/view/274, journal name: Recoletos Multidisciplinary Research Journal Vol. 6 No. 1'} \n",
      "\n",
      "Result 3:  {'uuid': '320d064c-63c9-4f86-b02d-f0631a6973af', 'author': 'Claudette Arcelon Baluran, Nancy Simoy Surmieda', 'distance': 0.2418765276670456, 'title': 'Discursive Strategies in Negotiating Power: The Case of a Female Radio Show Host', 'published_date': '2017-10-11 October 11, 2017', 'text': 'title: Discursive Strategies in Negotiating Power: The Case of a Female Radio Show Host, keywords: media discourse, discourse strategies, power, solidarity, author: Claudette Arcelon Baluran, Nancy Simoy Surmieda, doi: https://doi.org/10.32871/rmrj1705.01.03, abstract: Language as a major contestation site for power can manifest linguistic behavior between sexes to negotiate their power.Â  Framed within the poststructuralist framework, this study explored a female radio hostâ€™s discursive strategies to negotiate power in the context of Philippine media.Â  Dominant discourse strategies identified include topic control, utterance length, minimal response, and overlapping.Â  Topic control was utilized to dominate the flow of discourse while utterance length was used to minimize turns thereby allowing the female host to establish dominance during the live conversations. Although considered a weak discourse strategy, minimal responses were used not solely for the purpose of solidarity but to introduce the female radio show hostâ€™s ideas.Â  Overlapping was another strategy identified to control and negotiate power.Â  On an interesting note, prosodic elements were found to be likewise used to negotiate power.Â  The study sheds light on previously claimed weak discourse strategies identified with women.Â  Weak language in this study as well as discourse strategies associated with men has been found to be used by women as means to an endâ€”asÂ  a strategy to negotiate positions of dominance within power relations involving the opposite sex., published date: 2017-10-11, link: https://rmrj.usjr.edu.ph/rmrj/index.php/RMRJ/article/view/242, journal name: Recoletos Multidisciplinary Research Journal Vol. 5 No. 1'} \n",
      "\n",
      "Result 4:  {'uuid': '6281ce43-1b00-40d4-b9d5-8fc8892c09ef', 'author': 'Joje Mar P. Sanchez', 'distance': 0.2460058629512787, 'title': 'Development of Science Research Culture in Basic Education: A Theory Generation', 'published_date': '2022-06-27 June 27, 2022', 'text': 'title: Development of Science Research Culture in Basic Education: A Theory Generation, keywords: basic education, deductive-axiomatic theory generation, science investigatory projects, science research culture, author: Joje Mar P. Sanchez, doi: https://doi.org/10.32871/rmrj2210.01.10, abstract: Science research culture in basic education can be associated with science investigatory projects (SIPs). In relation to this, the paper establishes a theory on the development of SIP culture in basic education utilizing theory generation through axiomatic deductive approach based on steps prescribed by R. Padua (personal communication, November 17, 2014) which creates the theory that basic education institutions contribute to high productivity in SIPs. Simply because humans and non-human resources along with quality Science instruction are needed to yield such productivity. These attributes, resources, and Science instruction foster SIP culture. These are crucial aspects as schools capacitate students and teachers, produce the SIPs, and eventually disseminate these projects in science fairs., published date: 2022-06-27, link: https://rmrj.usjr.edu.ph/rmrj/index.php/RMRJ/article/view/1086, journal name: Recoletos Multidisciplinary Research Journal Vol. 10 No. 1'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, result in enumerate(final_results):\n",
    "    print(f\"Result {i}: \", result,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60e4af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
